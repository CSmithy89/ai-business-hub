# AG-UI (Agent-User Interface) Protocol Specification

> **⚠️ NOTE: SUPERSEDED BY COPILOTKIT**
> As of December 2025, the custom SSE implementation described in this document has been superseded by the **CopilotKit Protocol**. 
> While the concepts (Text Chunks, Tool Calls, UI Hints) remain valid, we now use the `CopilotKitSDK` and `@copilotkit/react-core` to handle the transport and state synchronization layers. 
> See `docs/architecture/dynamic-module-system.md` for the updated "Hybrid" architecture.

**Status:** Deprecated (Concepts preserved in CopilotKit)
**Protocol Version:** 0.1.0
**Target Framework:** CopilotKit + Next.js

---

## 1. Overview

**AG-UI** is a streaming protocol designed to deliver rich, real-time agent interactions to a frontend user interface. Unlike standard REST APIs that return a single JSON blob, AG-UI streams typed events (Server-Sent Events) to allow the UI to render:

*   Progressive text generation (typing effect).
*   Tool execution states (loading spinners, args display).
*   Rich UI components (charts, tables, forms).
*   Errors and status updates.

---

## 2. Transport

**Protocol:** Server-Sent Events (SSE)
**Content-Type:** `text/event-stream`
**Encoding:** UTF-8

### Connection

Client initiates a GET or POST request with `Accept: text/event-stream`.
Server responds with `200 OK` and keeps the connection open.

---

## 3. Event Types

Events are JSON objects prefixed with `data: `.

### 3.1 `RUN_STARTED`
Emitted when the agent begins processing a request.

```json
{
  "type": "RUN_STARTED",
  "runId": "run_12345",
  "agentId": "agent_crm",
  "timestamp": 1700000000
}
```

### 3.2 `TEXT_MESSAGE_CHUNK`
Emitted for every token/chunk of text generated by the LLM.

```json
{
  "type": "TEXT_MESSAGE_CHUNK",
  "delta": "Hello ",
  "messageId": "msg_abc123"
}
```

### 3.3 `TOOL_CALL_START`
Emitted when the agent decides to call a tool.

```json
{
  "type": "TOOL_CALL_START",
  "toolCallId": "call_987",
  "toolName": "search_contacts",
  "args": { "query": "Alice" }
}
```

### 3.4 `TOOL_CALL_RESULT`
Emitted when a tool finishes execution.

```json
{
  "type": "TOOL_CALL_RESULT",
  "toolCallId": "call_987",
  "result": { "email": "alice@example.com" },
  "isError": false
}
```

### 3.5 `RUN_FINISHED`
Emitted when the agent execution is complete.

```json
{
  "type": "RUN_FINISHED",
  "runId": "run_12345",
  "status": "success",
  "usage": { "input_tokens": 50, "output_tokens": 100 }
}
```

### 3.6 `ERROR`
Emitted on fatal errors.

```json
{
  "type": "ERROR",
  "code": "INTERNAL_ERROR",
  "message": "Database connection failed",
  "details": {}
}
```

---

## 4. Implementation Guidelines

### 4.1 Python (Backend - AgentOS)

We use the `EventEncoder` class to map internal Agno events to this protocol.

```python
# agents/ag_ui/encoder.py (Reference Implementation)

class EventEncoder:
    def encode(self, event_type: str, data: dict) -> str:
        payload = json.dumps({"type": event_type, **data})
        return f"data: {payload}\n\n"

# In FastAPI Route
@router.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    async def generator():
        # 1. Start
        yield encoder.encode("RUN_STARTED", {"runId": run_id})
        
        # 2. Stream Agno chunks
        async for chunk in agent.run_stream(request.message):
            if isinstance(chunk, ToolCall):
                 yield encoder.encode("TOOL_CALL_START", {{}})
            else:
                 yield encoder.encode("TEXT_MESSAGE_CHUNK", {"delta": chunk.content})
        
        # 3. Finish
        yield encoder.encode("RUN_FINISHED", {{}})

    return StreamingResponse(generator(), media_type="text/event-stream")
```

### 4.2 React (Frontend - Next.js)

The frontend consumes the stream and updates state.

```typescript
// useAgUi.ts (Concept)

const connect = async (message: string) => {
  const response = await fetch('/api/agents/chat/stream', {
    method: 'POST',
    body: JSON.stringify({ message })
  });

  const reader = response.body.getReader();
  const decoder = new TextDecoder();

  while (true) {
    const { done, value } = await reader.read();
    if (done) break;
    
    const chunk = decoder.decode(value);
    const lines = chunk.split('\n\n');
    
    for (const line of lines) {
      if (line.startsWith('data: ')) {
        const event = JSON.parse(line.slice(6));
        handleEvent(event);
      }
    }
  }
};

const handleEvent = (event) => {
  switch (event.type) {
    case 'TEXT_MESSAGE_CHUNK':
      setMessages(prev => updateLastMessage(prev, event.delta));
      break;
    case 'TOOL_CALL_START':
      setToolStatus(event.toolName, 'running');
      break;
    // ...
  }
};
```

---

## 5. UI Rendering Hints

Agents can return "Hints" to tell the UI to render specific components.

**Event:** `UI_RENDER_HINT`

```json
{
  "type": "UI_RENDER_HINT",
  "component": "StockChart",
  "props": {
    "symbol": "AAPL",
    "data": [...] 
  }
}
```

The frontend map:
```typescript
const COMPONENT_MAP = {
  StockChart: (props) => <StockChart {...props} />,
  ContactCard: (props) => <ContactCard {...props} />
};
```

---

## 6. Future Extensions

*   **Binary Streaming:** Support for audio/video chunks within the stream.
*   **Bidirectional:** Using WebSockets instead of SSE for interruptibility (User can click "Stop" to halt the agent immediately).
